{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapper Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d14c5b3dce942b88938ec216610273d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9d713a1ff942d6a4fe663f1c629246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56cb27bebe84a5091e01ed848f0d6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56180b6f98414396a2b6a5e63282b9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UmFkaW9CdXR0b25zKGRlc2NyaXB0aW9uPXUnRGF0YSBTZXQ6Jywgb3B0aW9ucz0oJ0JpYmxlJywgJ1RydW1wJywgJ0xpbFV6aVZlcnQnLCAnTGludXgnLCAnQXRvQ2tleXMnLCAnRHRvR2tleXPigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf2\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from model import Model\n",
    "#from mymodel import myModel\n",
    "#Select a DataSet\n",
    "#saved_dir = \"./\" + \"save_bible\"\n",
    "#saved_dir = \"./\" + \"save_rap01_high_bpm\"\n",
    "#saved_dir = \"./\" + \"save_BiggerRapLyrics\"\n",
    "saved_dir = \"./\" + \"save_reuters-newswire-2017-v5-fakenews\"\n",
    "#saved_dir = \"./\" + \"save_trump_nonum\"\n",
    "#saved_dir = \"./\" + \"save_LilUziVert\"\n",
    "#Select the number of suggested words\n",
    "num_of_suggested_words = 50\n",
    "\n",
    "#import argparse\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "args_n = 128\n",
    "args_prim = 'g'\n",
    "args_sample = 1\n",
    "\n",
    "text                   = widgets.Text()\n",
    "text2                  = widgets.Textarea()\n",
    "text_saved_config      = widgets.Textarea()\n",
    "saved_data             = widgets.RadioButtons(\n",
    "                            options=['Bible','Trump','LilUziVert','Linux','AtoCkeys',\n",
    "                                     'DtoGkeys','under2_5min','over2_5mi','120to160bpm','70to110bpm',\n",
    "                                     'BiggerRap','RAP_high_bpm','TravisScott'],\n",
    "                            description='Data Set:',\n",
    "                            disabled=False\n",
    "                        )\n",
    "#text.value = \"Jonny said \"\n",
    "display(text,text2,text_saved_config,saved_data)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    tf.reset_default_graph()\n",
    "    if(saved_data.value == 'Bible'):\n",
    "        saved_dir = \"./\" + \"save_bible\"\n",
    "    elif(saved_data.value == 'Trump'):\n",
    "        saved_dir = \"./\" + \"save_trump_nonum\"\n",
    "    elif(saved_data.value == 'LilUziVert'):\n",
    "        saved_dir = \"./\" + \"save_LilUziVert\"\n",
    "    elif(saved_data.value == 'Linux'):\n",
    "        saved_dir = \"./\" + \"save_Linux\"\n",
    "    elif(saved_data.value == 'AtoCkeys'):\n",
    "        saved_dir = \"./\" + \"save_AtoCkeys\"\n",
    "    elif(saved_data.value == 'DtoGkeys'):\n",
    "        saved_dir = \"./\" + \"save_DtoGkeys\"\n",
    "    elif(saved_data.value == 'under2_5min'):\n",
    "        saved_dir = \"./\" + \"save_under2_5min\"\n",
    "    elif(saved_data.value == 'over2_5min'):\n",
    "        saved_dir = \"./\" + \"save_over2_5min\"      \n",
    "    elif(saved_data.value == '120to160bpm'):\n",
    "        saved_dir = \"./\" + \"save_120to160bpm\"\n",
    "    elif(saved_data.value == '70to110bpm'):\n",
    "        saved_dir = \"./\" + \"save_70to110bpm\"       \n",
    "    elif(saved_data.value == 'BiggerRap'):\n",
    "        saved_dir = \"./\" + \"save_BiggerRapLyrics2\"      \n",
    "    elif(saved_data.value == 'RAP_high_bpm'):\n",
    "        saved_dir = \"./\" + \"save_rap01_high_bpm2\"\n",
    "    elif(saved_data.value == 'TravisScott'):\n",
    "        saved_dir = \"./\" + \"save_TravisScott\"  \n",
    "        \n",
    "        \n",
    "        \n",
    "    if(text.value.endswith(' ')):\n",
    "        with open(os.path.join(saved_dir, 'config.pkl'), 'rb') as f:\n",
    "            saved_args = cPickle.load(f)\n",
    "            mystring = ''\n",
    "        my_saved_args = saved_args\n",
    "        for item in vars(saved_args):\n",
    "            mystring_tmp = item, getattr(saved_args, item)\n",
    "            mystring = mystring + str(mystring_tmp) + '\\n'\n",
    "            #print mystring\n",
    "        text_saved_config.value = mystring\n",
    "        with open(os.path.join(saved_dir, 'chars_vocab.pkl'), 'rb') as f:\n",
    "            chars, vocab = cPickle.load(f)\n",
    "        model   = Model(saved_args,training=False)\n",
    "        #my2Model = myModel( my_saved_args)\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            ckpt = tf.train.get_checkpoint_state(saved_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                args_prime = text.value\n",
    "                #ISO-8859-1\n",
    "                data = model.sample(sess, chars, vocab, args_n, args_prime,args_sample).encode('UTF-8') #.encode('utf-8')\n",
    "                #text2.value = data.decode(\"utf-8\").split()[:3] #data.decode(\"utf-8\") #text.value\n",
    "                text2_value = ' '.join(data.decode(\"UTF-8\").split()[:len(text.value.split()) + num_of_suggested_words])\n",
    "                splits = text2_value.split()\n",
    "                my_string = \"\"\n",
    "                for split in splits:\n",
    "                    if ((split.find(\"(\") >= 0) and (split.find(\")\") >= 0)):\n",
    "                        my_string += \"\\n\"\n",
    "                        my_string += split\n",
    "                        my_string += \"\\n\"\n",
    "                    elif  (split.find(\"(\") >= 0):\n",
    "                        my_string += \"\\n\"\n",
    "                        my_string += split\n",
    "                    elif  (split.find(\")\") >= 0):\n",
    "                        my_string += \" \"\n",
    "                        my_string += split\n",
    "                        my_string += \"\\n\"\n",
    "                    else:\n",
    "                        my_string += \" \"\n",
    "                        my_string += split\n",
    "                #text2.value = my_string\n",
    "                text2.value = data\n",
    "#text.on_submit(handle_submit)\n",
    "text.observe(handle_submit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
